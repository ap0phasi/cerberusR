---
title: "R Notebook"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

```{r}
rm(list=ls())
library(dplyr)
library(abind)
library(keras)
library(tensorflow)

```


First we pull in some sample timeseries, in this case we will use the climate timeseries from https://www.kaggle.com/datasets/mnassrib/jena-climate

```{r}
time_series_data <- read.csv("../data/jena_climate_2009_2016.csv")
```

I will just pull the first bit of data for demo
```{r}
time_series_data <- time_series_data[1:6000,]
```

Clean up the data:
```{r}
names(time_series_data)=gsub("[.]","",names(time_series_data))
time_series_data[[1]]=as.POSIXct(time_series_data[[1]],format="%d.%m.%Y %H:%M:%S")
names(time_series_data)[1]="timestamp"
```

Cerberus works off call, context, and response. Users can specify the resolution and window size for call, response, and contexts. We also provide the units. The size of context_ts also gives us how many context heads to use. 
```{r}
source("../R/preprocess_functions.R")

config <- cerberus_config(
            call_feature_indx = 2:15,
            res_feature_indx = c(2,3,6),
            context_feature_indx = 2:15,
            res_units = "hours",
            call_ts = 2,
            call_size = 48,
            res_ts = 2,
            res_size = 12,
            context_ts = c(6,12),
            context_size = c(12,4)
)

prepared_data <- prepare_inputs(time_series_data,
                                config = config)

training_all <- grab_train_samples(prepared_data$formatted_all,0.7)
```


Load in functions
```{r}
source("../R/build_cerberus.R")
```

And finally we can build and train our neural network
```{r}
model <- build_cerberus(training_all, 64)
if (file.exists("../data/cerberus_weights.RdA")){
  keras::set_weights(model,readRDS("../data/cerberus_weights.RdA"))
}else{
  model <- train_cerberus(model, training_all, epochs = 50)
}

```
```{r}
training_res = (model %>% predict(c(list(training_all$inputs$train_call),
                                    training_all$inputs$train_cont,
                                    list(training_all$inputs$train_res))))
image(training_res)
image(training_all$outputs)
print(paste0("Training RMSE: ",sqrt(mean((training_res-training_all$outputs)^2))))
```
```{r}
all_res = (model %>% predict(c(list(prepared_data$formatted_all$inputs$x_call),
                               prepared_data$formatted_all$inputs$x_cont,
                               list(prepared_data$formatted_all$inputs$x_res))))
image(all_res)
image(prepared_data$formatted_all$outputs)
print(paste0("All RMSE: ",sqrt(mean((all_res-prepared_data$formatted_all$outputs)^2))))
```

Now we have to evaluate it generatively, meaning we first give it a timestamp with no response, make it come up with a single prediction, pass that in as the response, and continue. 
```{r}
call_size = config$call_size
call_features = config$call_features
resampled_time_series = prepared_data$resampled_time_series
context_size = config$context_size
context_feature_indx = config$context_feature_indx
call_feature_indx = config$call_feature_indx
res_feature_indx = config$res_feature_indx
features = names(prepared_data$scaled_data)
context_features <- features[context_feature_indx]
call_features <- features[call_feature_indx]
res_features <- features[res_feature_indx]
context_len <- length(context_size)

generate_in <-function(responses,timestamp){
  res_head_base <- responses

  call_head <- assign_call(resampled_time_series$call_resamp,timestamp,call_size,call_features)
  context_heads = list()
  for (icontext in 1:length(context_size)){
    context_heads[[paste0("context_",icontext)]]<-  assign_call(resampled_time_series[[sprintf("context_%s_resamp",icontext)]],
                                                                timestamp,
                                                                context_size[icontext],
                                                                context_features)
  }
  test_in <- list(c(list(call = call_head),
                  list(res = res_head_base),
                  context_heads))
  test_call=abind(lapply(test_in,function(x)array_reshape(x$call,c(1,call_size,length(call_features),1))),along = 1)
  test_res=abind(lapply(test_in,function(x)array_reshape(x$res,c(1,res_size,length(res_features),1))),along = 1)
  test_cont=list()
  for (icl in 1:context_len){
    test_cont[[paste0("context",icl)]]=abind(lapply(test_in,function(x)array_reshape(x[[paste0("context_",icl)]],c(1,context_size[icl],length(context_features),1))),along = 1)
  }
  names(test_cont)=NULL
  return(c(list(test_call),test_cont,list(test_res)))
}

res_size = dim(prepared_data$formatted_all$inputs$x_res)[2]
res_fl = dim(prepared_data$formatted_all$inputs$x_res)[3]
responses = matrix(0,nrow=res_size,ncol=res_fl)

timestamp <- tail(resampled_time_series$res_resamp$timestamp,sample(12:50,1))[1]

for (icount in 1:res_size){
  testres=(model %>% predict(generate_in(responses,timestamp)))
  responses[icount,]=testres
}

start_index = which(resampled_time_series$res_resamp$timestamp==timestamp)
end_index = start_index+res_size-1
actual = resampled_time_series$res_resamp[start_index:end_index,res_features]

matplot(actual,type="l",lwd=2)
matpoints(responses,type="l",lwd=1)
```
